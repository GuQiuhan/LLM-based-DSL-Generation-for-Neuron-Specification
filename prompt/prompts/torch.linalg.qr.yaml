api: torch.linalg.qr
doc: "\n\ntorch.linalg.qr(A, mode='reduced', *, out=None)\xB6\nComputes the QR decomposition\
  \ of a matrix.\nLetting K\\mathbb{K}K be R\\mathbb{R}R or C\\mathbb{C}C,\nthe full\
  \ QR decomposition of a matrix\nA\u2208Km\xD7nA \\in \\mathbb{K}^{m \\times n}A\u2208\
  Km\xD7n is defined as\n\nA=QRQ\u2208Km\xD7m,R\u2208Km\xD7nA = QR\\mathrlap{\\qquad\
  \ Q \\in \\mathbb{K}^{m \\times m}, R \\in \\mathbb{K}^{m \\times n}}A=QRQ\u2208\
  Km\xD7m,R\u2208Km\xD7nwhere QQQ is orthogonal in the real case and unitary in the\
  \ complex case,\nand RRR is upper triangular with real diagonal (even in the complex\
  \ case).\nWhen m > n (tall matrix), as R is upper triangular, its last m - n rows\
  \ are zero.\nIn this case, we can drop the last m - n columns of Q to form the\n\
  reduced QR decomposition:\n\nA=QRQ\u2208Km\xD7n,R\u2208Kn\xD7nA = QR\\mathrlap{\\\
  qquad Q \\in \\mathbb{K}^{m \\times n}, R \\in \\mathbb{K}^{n \\times n}}A=QRQ\u2208\
  Km\xD7n,R\u2208Kn\xD7nThe reduced QR decomposition agrees with the full QR decomposition\
  \ when n >= m (wide matrix).\nSupports input of float, double, cfloat and cdouble\
  \ dtypes.\nAlso supports batches of matrices, and if A is a batch of matrices then\n\
  the output has the same batch dimensions.\nThe parameter mode chooses between the\
  \ full and reduced QR decomposition.\nIf A has shape (*, m, n), denoting k = min(m,\
  \ n)\n\nmode= \u2018reduced\u2019 (default): Returns (Q, R) of shapes (*, m, k),\
  \ (*, k, n) respectively.\nIt is always differentiable.\nmode= \u2018complete\u2019\
  : Returns (Q, R) of shapes (*, m, m), (*, m, n) respectively.\nIt is differentiable\
  \ for m <= n.\nmode= \u2018r\u2019: Computes only the reduced R. Returns (Q, R)\
  \ with Q empty and R of shape (*, k, n).\nIt is never differentiable.\n\nDifferences\
  \ with numpy.linalg.qr:\n\nmode= \u2018raw\u2019 is not implemented.\nUnlike numpy.linalg.qr,\
  \ this function always returns a tuple of two tensors.\nWhen mode= \u2018r\u2019\
  , the Q tensor is an empty tensor.\n\n\nWarning\nThe elements in the diagonal of\
  \ R are not necessarily positive.\nAs such, the returned QR decomposition is only\
  \ unique up to the sign of the diagonal of R.\nTherefore, different platforms, like\
  \ NumPy, or inputs on different devices,\nmay produce different valid decompositions.\n\
  \n\nWarning\nThe QR decomposition is only well-defined if the first k = min(m, n)\
  \ columns\nof every matrix in A are linearly independent.\nIf this condition is\
  \ not met, no error will be thrown, but the QR produced\nmay be incorrect and its\
  \ autodiff may fail or produce incorrect results.\n\n\nParameters\n\nA (Tensor)\
  \ \u2013 tensor of shape (*, m, n) where * is zero or more batch dimensions.\nmode\
  \ (str, optional) \u2013 one of \u2018reduced\u2019, \u2018complete\u2019, \u2018\
  r\u2019.\nControls the shape of the returned tensors. Default: \u2018reduced\u2019\
  .\n\n\nKeyword Arguments\nout (tuple, optional) \u2013 output tuple of two tensors.\
  \ Ignored if None. Default: None.\n\nReturns\nA named tuple (Q, R).\n\n\nExamples:\n\
  >>> A = torch.tensor([[12., -51, 4], [6, 167, -68], [-4, 24, -41]])\n>>> Q, R =\
  \ torch.linalg.qr(A)\n>>> Q\ntensor([[-0.8571,  0.3943,  0.3314],\n        [-0.4286,\
  \ -0.9029, -0.0343],\n        [ 0.2857, -0.1714,  0.9429]])\n>>> R\ntensor([[ -14.0000,\
  \  -21.0000,   14.0000],\n        [   0.0000, -175.0000,   70.0000],\n        [\
  \   0.0000,    0.0000,  -35.0000]])\n>>> (Q @ R).round()\ntensor([[  12.,  -51.,\
  \    4.],\n        [   6.,  167.,  -68.],\n        [  -4.,   24.,  -41.]])\n>>>\
  \ (Q.T @ Q).round()\ntensor([[ 1.,  0.,  0.],\n        [ 0.,  1., -0.],\n      \
  \  [ 0., -0.,  1.]])\n>>> Q2, R2 = torch.linalg.qr(A, mode='r')\n>>> Q2\ntensor([])\n\
  >>> torch.equal(R, R2)\nTrue\n>>> A = torch.randn(3, 4, 5)\n>>> Q, R = torch.linalg.qr(A,\
  \ mode='complete')\n>>> torch.dist(Q @ R, A)\ntensor(1.6099e-06)\n>>> torch.dist(Q.mT\
  \ @ Q, torch.eye(4))\ntensor(6.2158e-07)\n\n\n"
