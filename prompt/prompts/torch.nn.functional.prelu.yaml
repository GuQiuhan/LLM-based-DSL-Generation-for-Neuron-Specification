api: torch.nn.functional.prelu
doc: "\n\ntorch.nn.functional.prelu(input, weight) \u2192 Tensor\xB6\nApplies element-wise\
  \ the function\nPReLU(x)=max\u2061(0,x)+weight\u2217min\u2061(0,x)\\text{PReLU}(x)\
  \ = \\max(0,x) + \\text{weight} * \\min(0,x)PReLU(x)=max(0,x)+weight\u2217min(0,x)\
  \ where weight is a\nlearnable parameter.\n\nNote\nweight is expected to be a scalar\
  \ or 1-D tensor. If weight is 1-D,\nits size must match the number of input channels,\
  \ determined by\ninput.size(1) when input.dim() >= 2, otherwise 1.\nIn the 1-D case,\
  \ note that when input has dim > 2, weight can be expanded\nto the shape of input\
  \ in a way that is not possible using normal\nbroadcasting semantics.\n\nSee PReLU\
  \ for more details.\n"
