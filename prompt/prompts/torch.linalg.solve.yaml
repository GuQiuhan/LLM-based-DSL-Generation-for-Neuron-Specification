api: torch.linalg.solve
doc: "\n\ntorch.linalg.solve(A, B, *, left=True, out=None) \u2192 Tensor\xB6\nComputes\
  \ the solution of a square system of linear equations with a unique solution.\n\
  Letting K\\mathbb{K}K be R\\mathbb{R}R or C\\mathbb{C}C,\nthis function computes\
  \ the solution X\u2208Kn\xD7kX \\in \\mathbb{K}^{n \\times k}X\u2208Kn\xD7k of the\
  \ linear system associated to\nA\u2208Kn\xD7n,B\u2208Kn\xD7kA \\in \\mathbb{K}^{n\
  \ \\times n}, B \\in \\mathbb{K}^{n \\times k}A\u2208Kn\xD7n,B\u2208Kn\xD7k, which\
  \ is defined as\n\nAX=BAX = B\n\nAX=BIf left= False, this function returns the matrix\
  \ X\u2208Kn\xD7kX \\in \\mathbb{K}^{n \\times k}X\u2208Kn\xD7k that solves the system\n\
  \nXA=BA\u2208Kk\xD7k,B\u2208Kn\xD7k.XA = B\\mathrlap{\\qquad A \\in \\mathbb{K}^{k\
  \ \\times k}, B \\in \\mathbb{K}^{n \\times k}.}XA=BA\u2208Kk\xD7k,B\u2208Kn\xD7\
  k.This system of linear equations has one solution if and only if AAA is invertible.\n\
  This function assumes that AAA is invertible.\nSupports inputs of float, double,\
  \ cfloat and cdouble dtypes.\nAlso supports batches of matrices, and if the inputs\
  \ are batches of matrices then\nthe output has the same batch dimensions.\nLetting\
  \ * be zero or more batch dimensions,\n\nIf A has shape (*, n, n) and B has shape\
  \ (*, n) (a batch of vectors) or shape\n(*, n, k) (a batch of matrices or \u201C\
  multiple right-hand sides\u201D), this function returns X of shape\n(*, n) or (*,\
  \ n, k) respectively.\nOtherwise, if A has shape (*, n, n) and  B has shape (n,)\
  \  or (n, k), B\nis broadcasted to have shape (*, n) or (*, n, k) respectively.\n\
  This function then returns the solution of the resulting batch of systems of linear\
  \ equations.\n\n\nNote\nThis function computes X = A.inverse() @ B in a faster and\n\
  more numerically stable way than performing the computations separately.\n\n\nNote\n\
  It is possible to compute the solution of the system XA=BXA = BXA=B by passing the\
  \ inputs\nA and B transposed and transposing the output returned by this function.\n\
  \n\nNote\nA is allowed to be a non-batched torch.sparse_csr_tensor, but only with\
  \ left=True.\n\n\nNote\nWhen inputs are on a CUDA device, this function synchronizes\
  \ that device with the CPU. For a version of this function that does not synchronize,\
  \ see torch.linalg.solve_ex().\n\n\nSee also\ntorch.linalg.solve_triangular() computes\
  \ the solution of a triangular system of linear\nequations with a unique solution.\n\
  \n\nParameters\n\nA (Tensor) \u2013 tensor of shape (*, n, n) where * is zero or\
  \ more batch dimensions.\nB (Tensor) \u2013 right-hand side tensor of shape (*,\
  \ n) or  (*, n, k) or (n,) or (n, k)\naccording to the rules described above\n\n\
  \nKeyword Arguments\n\nleft (bool, optional) \u2013 whether to solve the system\
  \ AX=BAX=BAX=B or XA=BXA = BXA=B. Default: True.\nout (Tensor, optional) \u2013\
  \ output tensor. Ignored if None. Default: None.\n\n\nRaises\nRuntimeError \u2013\
  \ if the A matrix is not invertible or any matrix in a batched A\n    is not invertible.\n\
  \n\nExamples:\n>>> A = torch.randn(3, 3)\n>>> b = torch.randn(3)\n>>> x = torch.linalg.solve(A,\
  \ b)\n>>> torch.allclose(A @ x, b)\nTrue\n>>> A = torch.randn(2, 3, 3)\n>>> B =\
  \ torch.randn(2, 3, 4)\n>>> X = torch.linalg.solve(A, B)\n>>> X.shape\ntorch.Size([2,\
  \ 3, 4])\n>>> torch.allclose(A @ X, B)\nTrue\n\n>>> A = torch.randn(2, 3, 3)\n>>>\
  \ b = torch.randn(3, 1)\n>>> x = torch.linalg.solve(A, b) # b is broadcasted to\
  \ size (2, 3, 1)\n>>> x.shape\ntorch.Size([2, 3, 1])\n>>> torch.allclose(A @ x,\
  \ b)\nTrue\n>>> b = torch.randn(3)\n>>> x = torch.linalg.solve(A, b) # b is broadcasted\
  \ to size (2, 3)\n>>> x.shape\ntorch.Size([2, 3])\n>>> Ax = A @ x.unsqueeze(-1)\n\
  >>> torch.allclose(Ax, b.unsqueeze(-1).expand_as(Ax))\nTrue\n\n\n"
