api: torch.nn.functional.embedding_bag
doc: "\n\ntorch.nn.functional.embedding_bag(input, weight, offsets=None, max_norm=None,\
  \ norm_type=2, scale_grad_by_freq=False, mode='mean', sparse=False, per_sample_weights=None,\
  \ include_last_offset=False, padding_idx=None)[source]\xB6\nCompute sums, means\
  \ or maxes of bags of embeddings.\nCalculation is done without instantiating the\
  \ intermediate embeddings.\nSee torch.nn.EmbeddingBag for more details.\n\nNote\n\
  This operation may produce nondeterministic gradients when given tensors on a CUDA\
  \ device. See Reproducibility for more information.\n\n\nParameters\n\ninput (LongTensor)\
  \ \u2013 Tensor containing bags of indices into the embedding matrix\nweight (Tensor)\
  \ \u2013 The embedding matrix with number of rows equal to the maximum possible\
  \ index + 1,\nand number of columns equal to the embedding size\noffsets (LongTensor,\
  \ optional) \u2013 Only used when input is 1D. offsets determines\nthe starting\
  \ index position of each bag (sequence) in input.\nmax_norm (float, optional) \u2013\
  \ If given, each embedding vector with norm larger than max_norm\nis renormalized\
  \ to have norm max_norm.\nNote: this will modify weight in-place.\nnorm_type (float,\
  \ optional) \u2013 The p in the p-norm to compute for the max_norm option.\nDefault\
  \ 2.\nscale_grad_by_freq (bool, optional) \u2013 if given, this will scale gradients\
  \ by the inverse of frequency of\nthe words in the mini-batch. Default False.\n\
  Note: this option is not supported when mode=\"max\".\nmode (str, optional) \u2013\
  \ \"sum\", \"mean\" or \"max\". Specifies the way to reduce the bag.\nDefault: \"\
  mean\"\nsparse (bool, optional) \u2013 if True, gradient w.r.t. weight will be a\
  \ sparse tensor. See Notes under\ntorch.nn.Embedding for more details regarding\
  \ sparse gradients.\nNote: this option is not supported when mode=\"max\".\nper_sample_weights\
  \ (Tensor, optional) \u2013 a tensor of float / double weights, or None\nto indicate\
  \ all weights should be taken to be 1. If specified, per_sample_weights\nmust have\
  \ exactly the same shape as input and is treated as having the same\noffsets, if\
  \ those are not None.\ninclude_last_offset (bool, optional) \u2013 if True, the\
  \ size of offsets is equal to the number of bags + 1.\nThe last element is the size\
  \ of the input, or the ending index position of the last bag (sequence).\npadding_idx\
  \ (int, optional) \u2013 If specified, the entries at padding_idx do not contribute\
  \ to the\ngradient; therefore, the embedding vector at padding_idx is not updated\n\
  during training, i.e. it remains as a fixed \u201Cpad\u201D. Note that the embedding\n\
  vector at padding_idx is excluded from the reduction.\n\n\nReturn type\nTensor\n\
  \n\n\nShape:\ninput (LongTensor) and offsets (LongTensor, optional)\n\nIf input\
  \ is 2D of shape (B, N), it will be treated as B bags (sequences)\neach of fixed\
  \ length N, and this will return B values aggregated in a way\ndepending on the\
  \ mode. offsets is ignored and required to be None in this case.\nIf input is 1D\
  \ of shape (N), it will be treated as a concatenation of\nmultiple bags (sequences).\
  \ offsets is required to be a 1D tensor containing\nthe starting index positions\
  \ of each bag in input. Therefore, for offsets\nof shape (B), input will be viewed\
  \ as having B bags.\nEmpty bags (i.e., having 0-length) will have returned vectors\
  \ filled by zeros.\n\n\nweight (Tensor): the learnable weights of the module of\
  \ shape (num_embeddings, embedding_dim)\nper_sample_weights (Tensor, optional).\
  \ Has the same shape as input.\noutput: aggregated embedding values of shape (B,\
  \ embedding_dim)\n\n\n\nExamples:\n>>> # an Embedding module containing 10 tensors\
  \ of size 3\n>>> embedding_matrix = torch.rand(10, 3)\n>>> # a batch of 2 samples\
  \ of 4 indices each\n>>> input = torch.tensor([1, 2, 4, 5, 4, 3, 2, 9])\n>>> offsets\
  \ = torch.tensor([0, 4])\n>>> F.embedding_bag(input, embedding_matrix, offsets)\n\
  tensor([[ 0.3397,  0.3552,  0.5545],\n        [ 0.5893,  0.4386,  0.5882]])\n\n\
  >>> # example with padding_idx\n>>> embedding_matrix = torch.rand(10, 3)\n>>> input\
  \ = torch.tensor([2, 2, 2, 2, 4, 3, 2, 9])\n>>> offsets = torch.tensor([0, 4])\n\
  >>> F.embedding_bag(input, embedding_matrix, offsets, padding_idx=2, mode='sum')\n\
  tensor([[ 0.0000,  0.0000,  0.0000],\n        [-0.7082,  3.2145, -2.6251]])\n\n\n"
