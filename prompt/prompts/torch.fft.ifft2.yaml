api: torch.fft.ifft2
doc: "\n\ntorch.fft.ifft2(input, s=None, dim=(-2, -1), norm=None, *, out=None) \u2192\
  \ Tensor\xB6\nComputes the 2 dimensional inverse discrete Fourier transform of input.\n\
  Equivalent to ifftn() but IFFTs only the last two dimensions by default.\n\nNote\n\
  Supports torch.half and torch.chalf on CUDA with GPU Architecture SM53 or greater.\n\
  However it only supports powers of 2 signal length in every transformed dimensions.\n\
  \n\nParameters\n\ninput (Tensor) \u2013 the input tensor\ns (Tuple[int], optional)\
  \ \u2013 Signal size in the transformed dimensions.\nIf given, each dimension dim[i]\
  \ will either be zero-padded or\ntrimmed to the length s[i] before computing the\
  \ IFFT.\nIf a length -1 is specified, no padding is done in that dimension.\nDefault:\
  \ s = [input.size(d) for d in dim]\ndim (Tuple[int], optional) \u2013 Dimensions\
  \ to be transformed.\nDefault: last two dimensions.\nnorm (str, optional) \u2013\
  \ Normalization mode. For the backward transform\n(ifft2()), these correspond to:\n\
  \n\"forward\" - no normalization\n\"backward\" - normalize by 1/n\n\"ortho\" - normalize\
  \ by 1/sqrt(n) (making the IFFT orthonormal)\n\nWhere n = prod(s) is the logical\
  \ IFFT size.\nCalling the forward transform (fft2()) with the same\nnormalization\
  \ mode will apply an overall normalization of 1/n between\nthe two transforms. This\
  \ is required to make ifft2()\nthe exact inverse.\nDefault is \"backward\" (normalize\
  \ by 1/n).\n\n\n\nKeyword Arguments\nout (Tensor, optional) \u2013 the output tensor.\n\
  \n\nExample\n>>> x = torch.rand(10, 10, dtype=torch.complex64)\n>>> ifft2 = torch.fft.ifft2(x)\n\
  \n\nThe discrete Fourier transform is separable, so ifft2()\nhere is equivalent\
  \ to two one-dimensional ifft() calls:\n>>> two_iffts = torch.fft.ifft(torch.fft.ifft(x,\
  \ dim=0), dim=1)\n>>> torch.testing.assert_close(ifft2, two_iffts, check_stride=False)\n\
  \n\n"
