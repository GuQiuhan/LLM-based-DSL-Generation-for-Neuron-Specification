api: torch.nn.functional.nll_loss
doc: "\n\ntorch.nn.functional.nll_loss(input, target, weight=None, size_average=None,\
  \ ignore_index=-100, reduce=None, reduction='mean')[source]\xB6\nCompute the negative\
  \ log likelihood loss.\nSee NLLLoss for details.\n\nParameters\n\ninput (Tensor)\
  \ \u2013 (N,C)(N, C)(N,C) where C = number of classes or (N,C,H,W)(N, C, H, W)(N,C,H,W)\n\
  in case of 2D Loss, or (N,C,d1,d2,...,dK)(N, C, d_1, d_2, ..., d_K)(N,C,d1\u200B\
  ,d2\u200B,...,dK\u200B) where K\u22651K \\geq 1K\u22651\nin the case of K-dimensional\
  \ loss. input is expected to be log-probabilities.\ntarget (Tensor) \u2013 (N)(N)(N)\
  \ where each value is 0\u2264targets[i]\u2264C\u221210 \\leq \\text{targets}[i]\
  \ \\leq C-10\u2264targets[i]\u2264C\u22121,\nor (N,d1,d2,...,dK)(N, d_1, d_2, ...,\
  \ d_K)(N,d1\u200B,d2\u200B,...,dK\u200B) where K\u22651K \\geq 1K\u22651 for\nK-dimensional\
  \ loss.\nweight (Tensor, optional) \u2013 a manual rescaling weight given to each\n\
  class. If given, has to be a Tensor of size C\nsize_average (bool, optional) \u2013\
  \ Deprecated (see reduction). By default,\nthe losses are averaged over each loss\
  \ element in the batch. Note that for\nsome losses, there multiple elements per\
  \ sample. If the field size_average\nis set to False, the losses are instead summed\
  \ for each minibatch. Ignored\nwhen reduce is False. Default: True\nignore_index\
  \ (int, optional) \u2013 Specifies a target value that is ignored\nand does not\
  \ contribute to the input gradient. When size_average is\nTrue, the loss is averaged\
  \ over non-ignored targets. Default: -100\nreduce (bool, optional) \u2013 Deprecated\
  \ (see reduction). By default, the\nlosses are averaged or summed over observations\
  \ for each minibatch depending\non size_average. When reduce is False, returns a\
  \ loss per\nbatch element instead and ignores size_average. Default: True\nreduction\
  \ (str, optional) \u2013 Specifies the reduction to apply to the output:\n'none'\
  \ | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the\
  \ output will be divided by the number of\nelements in the output, 'sum': the output\
  \ will be summed. Note: size_average\nand reduce are in the process of being deprecated,\
  \ and in the meantime,\nspecifying either of those two args will override reduction.\
  \ Default: 'mean'\n\n\nReturn type\nTensor\n\n\nExample:\n>>> # input is of size\
  \ N x C = 3 x 5\n>>> input = torch.randn(3, 5, requires_grad=True)\n>>> # each element\
  \ in target has to have 0 <= value < C\n>>> target = torch.tensor([1, 0, 4])\n>>>\
  \ output = F.nll_loss(F.log_softmax(input, dim=1), target)\n>>> output.backward()\n\
  \n\n"
