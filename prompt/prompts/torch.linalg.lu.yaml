api: torch.linalg.lu
doc: "\n\ntorch.linalg.lu(A, *, pivot=True, out=None)\xB6\nComputes the LU decomposition\
  \ with partial pivoting of a matrix.\nLetting K\\mathbb{K}K be R\\mathbb{R}R or\
  \ C\\mathbb{C}C,\nthe LU decomposition with partial pivoting of a matrix\nA\u2208\
  Km\xD7nA \\in \\mathbb{K}^{m \\times n}A\u2208Km\xD7n is defined as\n\nA=PLUP\u2208\
  Km\xD7m,L\u2208Km\xD7k,U\u2208Kk\xD7nA = PLU\\mathrlap{\\qquad P \\in \\mathbb{K}^{m\
  \ \\times m}, L \\in \\mathbb{K}^{m \\times k}, U \\in \\mathbb{K}^{k \\times n}}A=PLUP\u2208\
  Km\xD7m,L\u2208Km\xD7k,U\u2208Kk\xD7nwhere k = min(m,n), PPP is a permutation matrix,\
  \ LLL is lower triangular with ones on the diagonal\nand UUU is upper triangular.\n\
  If pivot= False and A is on GPU, then the LU decomposition without pivoting is computed\n\
  \nA=LUL\u2208Km\xD7k,U\u2208Kk\xD7nA = LU\\mathrlap{\\qquad L \\in \\mathbb{K}^{m\
  \ \\times k}, U \\in \\mathbb{K}^{k \\times n}}A=LUL\u2208Km\xD7k,U\u2208Kk\xD7\
  nWhen pivot= False, the returned matrix P will be empty.\nThe LU decomposition without\
  \ pivoting may not exist if any of the principal minors of A is singular.\nIn this\
  \ case, the output matrix may contain inf or NaN.\nSupports input of float, double,\
  \ cfloat and cdouble dtypes.\nAlso supports batches of matrices, and if A is a batch\
  \ of matrices then\nthe output has the same batch dimensions.\n\nSee also\ntorch.linalg.solve()\
  \ solves a system of linear equations using the LU decomposition\nwith partial pivoting.\n\
  \n\nWarning\nThe LU decomposition is almost never unique, as often there are different\
  \ permutation\nmatrices that can yield different LU decompositions.\nAs such, different\
  \ platforms, like SciPy, or inputs on different devices,\nmay produce different\
  \ valid decompositions.\n\n\nWarning\nGradient computations are only supported if\
  \ the input matrix is full-rank.\nIf this condition is not met, no error will be\
  \ thrown, but the gradient\nmay not be finite.\nThis is because the LU decomposition\
  \ with pivoting is not differentiable at these points.\n\n\nParameters\n\nA (Tensor)\
  \ \u2013 tensor of shape (*, m, n) where * is zero or more batch dimensions.\npivot\
  \ (bool, optional) \u2013 Controls whether to compute the LU decomposition with\
  \ partial pivoting or\nno pivoting. Default: True.\n\n\nKeyword Arguments\nout (tuple,\
  \ optional) \u2013 output tuple of three tensors. Ignored if None. Default: None.\n\
  \nReturns\nA named tuple (P, L, U).\n\n\nExamples:\n>>> A = torch.randn(3, 2)\n\
  >>> P, L, U = torch.linalg.lu(A)\n>>> P\ntensor([[0., 1., 0.],\n        [0., 0.,\
  \ 1.],\n        [1., 0., 0.]])\n>>> L\ntensor([[1.0000, 0.0000],\n        [0.5007,\
  \ 1.0000],\n        [0.0633, 0.9755]])\n>>> U\ntensor([[0.3771, 0.0489],\n     \
  \   [0.0000, 0.9644]])\n>>> torch.dist(A, P @ L @ U)\ntensor(5.9605e-08)\n\n>>>\
  \ A = torch.randn(2, 5, 7, device=\"cuda\")\n>>> P, L, U = torch.linalg.lu(A, pivot=False)\n\
  >>> P\ntensor([], device='cuda:0')\n>>> torch.dist(A, L @ U)\ntensor(1.0376e-06,\
  \ device='cuda:0')\n\n\n"
