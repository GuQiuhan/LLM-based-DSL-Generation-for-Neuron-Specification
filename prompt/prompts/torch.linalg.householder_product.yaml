api: torch.linalg.householder_product
doc: "\n\ntorch.linalg.householder_product(A, tau, *, out=None) \u2192 Tensor\xB6\n\
  Computes the first n columns of a product of Householder matrices.\nLet K\\mathbb{K}K\
  \ be R\\mathbb{R}R or C\\mathbb{C}C, and\nlet A\u2208Km\xD7nA \\in \\mathbb{K}^{m\
  \ \\times n}A\u2208Km\xD7n be a matrix with columns ai\u2208Kma_i \\in \\mathbb{K}^mai\u200B\
  \u2208Km\nfor i=1,\u2026,mi=1,\\ldots,mi=1,\u2026,m with m\u2265nm \\geq nm\u2265\
  n. Denote by bib_ibi\u200B the vector resulting from\nzeroing out the first i\u2212\
  1i-1i\u22121 components of aia_iai\u200B and setting to 1 the iii-th.\nFor a vector\
  \ \u03C4\u2208Kk\\tau \\in \\mathbb{K}^k\u03C4\u2208Kk with k\u2264nk \\leq nk\u2264\
  n, this function computes the\nfirst nnn columns of the matrix\n\nH1H2...HkwithHi=Im\u2212\
  \u03C4ibibiHH_1H_2 ... H_k \\qquad\\text{with}\\qquad H_i = \\mathrm{I}_m - \\tau_i\
  \ b_i b_i^{\\text{H}}H1\u200BH2\u200B...Hk\u200BwithHi\u200B=Im\u200B\u2212\u03C4\
  i\u200Bbi\u200BbiH\u200Bwhere Im\\mathrm{I}_mIm\u200B is the m-dimensional identity\
  \ matrix and bHb^{\\text{H}}bH is the\nconjugate transpose when bbb is complex,\
  \ and the transpose when bbb is real-valued.\nThe output matrix is the same size\
  \ as the input matrix A.\nSee Representation of Orthogonal or Unitary Matrices for\
  \ further details.\nSupports inputs of float, double, cfloat and cdouble dtypes.\n\
  Also supports batches of matrices, and if the inputs are batches of matrices then\n\
  the output has the same batch dimensions.\n\nSee also\ntorch.geqrf() can be used\
  \ together with this function to form the Q from the\nqr() decomposition.\ntorch.ormqr()\
  \ is a related function that computes the matrix multiplication\nof a product of\
  \ Householder matrices with another matrix.\nHowever, that function is not supported\
  \ by autograd.\n\n\nWarning\nGradient computations are only well-defined if \u03C4\
  i\u22601\u2223\u2223ai\u2223\u22232\\tau_i \\neq \\frac{1}{||a_i||^2}\u03C4i\u200B\
  \uE020=\u2223\u2223ai\u200B\u2223\u222321\u200B.\nIf this condition is not met,\
  \ no error will be thrown, but the gradient produced may contain NaN.\n\n\nParameters\n\
  \nA (Tensor) \u2013 tensor of shape (*, m, n) where * is zero or more batch dimensions.\n\
  tau (Tensor) \u2013 tensor of shape (*, k) where * is zero or more batch dimensions.\n\
  \n\nKeyword Arguments\nout (Tensor, optional) \u2013 output tensor. Ignored if None.\
  \ Default: None.\n\nRaises\nRuntimeError \u2013 if A doesn\u2019t satisfy the requirement\
  \ m >= n,\n    or tau doesn\u2019t satisfy the requirement n >= k.\n\n\nExamples:\n\
  >>> A = torch.randn(2, 2)\n>>> h, tau = torch.geqrf(A)\n>>> Q = torch.linalg.householder_product(h,\
  \ tau)\n>>> torch.dist(Q, torch.linalg.qr(A).Q)\ntensor(0.)\n\n>>> h = torch.randn(3,\
  \ 2, 2, dtype=torch.complex128)\n>>> tau = torch.randn(3, 1, dtype=torch.complex128)\n\
  >>> Q = torch.linalg.householder_product(h, tau)\n>>> Q\ntensor([[[ 1.8034+0.4184j,\
  \  0.2588-1.0174j],\n        [-0.6853+0.7953j,  2.0790+0.5620j]],\n\n        [[\
  \ 1.4581+1.6989j, -1.5360+0.1193j],\n        [ 1.3877-0.6691j,  1.3512+1.3024j]],\n\
  \n        [[ 1.4766+0.5783j,  0.0361+0.6587j],\n        [ 0.6396+0.1612j,  1.3693+0.4481j]]],\
  \ dtype=torch.complex128)\n\n\n"
