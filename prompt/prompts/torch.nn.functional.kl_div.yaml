api: torch.nn.functional.kl_div
doc: "\n\ntorch.nn.functional.kl_div(input, target, size_average=None, reduce=None,\
  \ reduction='mean', log_target=False)[source]\xB6\nCompute the KL Divergence loss.\n\
  Refer - The Kullback-Leibler divergence Loss\nSee KLDivLoss for details.\n\nParameters\n\
  \ninput (Tensor) \u2013 Tensor of arbitrary shape in log-probabilities.\ntarget\
  \ (Tensor) \u2013 Tensor of the same shape as input. See log_target for\nthe target\u2019\
  s interpretation.\nsize_average (bool, optional) \u2013 Deprecated (see reduction).\
  \ By default,\nthe losses are averaged over each loss element in the batch. Note\
  \ that for\nsome losses, there multiple elements per sample. If the field size_average\n\
  is set to False, the losses are instead summed for each minibatch. Ignored\nwhen\
  \ reduce is False. Default: True\nreduce (bool, optional) \u2013 Deprecated (see\
  \ reduction). By default, the\nlosses are averaged or summed over observations for\
  \ each minibatch depending\non size_average. When reduce is False, returns a loss\
  \ per\nbatch element instead and ignores size_average. Default: True\nreduction\
  \ (str, optional) \u2013 Specifies the reduction to apply to the output:\n'none'\
  \ | 'batchmean' | 'sum' | 'mean'.\n'none': no reduction will be applied\n'batchmean':\
  \ the sum of the output will be divided by the batchsize\n'sum': the output will\
  \ be summed\n'mean': the output will be divided by the number of elements in the\
  \ output\nDefault: 'mean'\nlog_target (bool) \u2013 A flag indicating whether target\
  \ is passed in the log space.\nIt is recommended to pass certain distributions (like\
  \ softmax)\nin the log space to avoid numerical issues caused by explicit log.\n\
  Default: False\n\n\nReturn type\nTensor\n\n\n\nNote\nsize_average and reduce are\
  \ in the process of being deprecated,\nand in the meantime, specifying either of\
  \ those two args will override reduction.\n\n\nWarning\nreduction = 'mean' doesn\u2019\
  t return the true kl divergence value, please use\nreduction = 'batchmean' which\
  \ aligns with KL math definition.\n\n"
