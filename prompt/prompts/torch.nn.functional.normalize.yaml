api: torch.nn.functional.normalize
doc: "\n\ntorch.nn.functional.normalize(input, p=2.0, dim=1, eps=1e-12, out=None)[source]\xB6\
  \nPerform LpL_pLp\u200B normalization of inputs over specified dimension.\nFor a\
  \ tensor input of sizes (n0,...,ndim,...,nk)(n_0, ..., n_{dim}, ..., n_k)(n0\u200B\
  ,...,ndim\u200B,...,nk\u200B), each\nndimn_{dim}ndim\u200B -element vector vvv along\
  \ dimension dim is transformed as\n\nv=vmax\u2061(\u2225v\u2225p,\u03F5).v = \\\
  frac{v}{\\max(\\lVert v \\rVert_p, \\epsilon)}.\n\nv=max(\u2225v\u2225p\u200B,\u03F5\
  )v\u200B.With the default arguments it uses the Euclidean norm over vectors along\
  \ dimension 111 for normalization.\n\nParameters\n\ninput (Tensor) \u2013 input\
  \ tensor of any shape\np (float) \u2013 the exponent value in the norm formulation.\
  \ Default: 2\ndim (int or tuple of ints) \u2013 the dimension to reduce. Default:\
  \ 1\neps (float) \u2013 small value to avoid division by zero. Default: 1e-12\n\
  out (Tensor, optional) \u2013 the output tensor. If out is used, this\noperation\
  \ won\u2019t be differentiable.\n\n\nReturn type\nTensor\n\n\n"
