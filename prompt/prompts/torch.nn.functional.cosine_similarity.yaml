api: torch.nn.functional.cosine_similarity
doc: "\n\ntorch.nn.functional.cosine_similarity(x1, x2, dim=1, eps=1e-8) \u2192 Tensor\xB6\
  \nReturns cosine similarity between x1 and x2, computed along dim. x1 and x2 must\
  \ be broadcastable\nto a common shape. dim refers to the dimension in this common\
  \ shape. Dimension dim of the output is\nsqueezed (see torch.squeeze()), resulting\
  \ in the\noutput tensor having 1 fewer dimension.\n\nsimilarity=x1\u22C5x2max\u2061\
  (\u2225x1\u22252,\u03F5)\u22C5max\u2061(\u2225x2\u22252,\u03F5)\\text{similarity}\
  \ = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2, \\epsilon) \\cdot \\max(\\\
  Vert x_2 \\Vert _2, \\epsilon)}\n\nsimilarity=max(\u2225x1\u200B\u22252\u200B,\u03F5\
  )\u22C5max(\u2225x2\u200B\u22252\u200B,\u03F5)x1\u200B\u22C5x2\u200B\u200BSupports\
  \ type promotion.\n\nParameters\n\nx1 (Tensor) \u2013 First input.\nx2 (Tensor)\
  \ \u2013 Second input.\ndim (int, optional) \u2013 Dimension along which cosine\
  \ similarity is computed. Default: 1\neps (float, optional) \u2013 Small value to\
  \ avoid division by zero.\nDefault: 1e-8\n\n\n\nExample:\n>>> input1 = torch.randn(100,\
  \ 128)\n>>> input2 = torch.randn(100, 128)\n>>> output = F.cosine_similarity(input1,\
  \ input2)\n>>> print(output)\n\n\n"
