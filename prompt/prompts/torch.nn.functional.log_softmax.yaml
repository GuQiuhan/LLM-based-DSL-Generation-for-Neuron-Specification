api: torch.nn.functional.log_softmax
doc: "\n\ntorch.nn.functional.log_softmax(input, dim=None, _stacklevel=3, dtype=None)[source]\xB6\
  \nApply a softmax followed by a logarithm.\nWhile mathematically equivalent to log(softmax(x)),\
  \ doing these two\noperations separately is slower and numerically unstable. This\
  \ function\nuses an alternative formulation to compute the output and gradient correctly.\n\
  See LogSoftmax for more details.\n\nParameters\n\ninput (Tensor) \u2013 input\n\
  dim (int) \u2013 A dimension along which log_softmax will be computed.\ndtype (torch.dtype,\
  \ optional) \u2013 the desired data type of returned tensor.\nIf specified, the\
  \ input tensor is cast to dtype before the operation\nis performed. This is useful\
  \ for preventing data type overflows. Default: None.\n\n\nReturn type\nTensor\n\n\
  \n"
