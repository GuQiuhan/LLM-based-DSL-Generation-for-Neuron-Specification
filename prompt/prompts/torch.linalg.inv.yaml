api: torch.linalg.inv
doc: "\n\ntorch.linalg.inv(A, *, out=None) \u2192 Tensor\xB6\nComputes the inverse\
  \ of a square matrix if it exists.\nThrows a RuntimeError if the matrix is not invertible.\n\
  Letting K\\mathbb{K}K be R\\mathbb{R}R or C\\mathbb{C}C,\nfor a matrix A\u2208Kn\xD7\
  nA \\in \\mathbb{K}^{n \\times n}A\u2208Kn\xD7n,\nits inverse matrix A\u22121\u2208\
  Kn\xD7nA^{-1} \\in \\mathbb{K}^{n \\times n}A\u22121\u2208Kn\xD7n (if it exists)\
  \ is defined as\n\nA\u22121A=AA\u22121=InA^{-1}A = AA^{-1} = \\mathrm{I}_nA\u2212\
  1A=AA\u22121=In\u200Bwhere In\\mathrm{I}_nIn\u200B is the n-dimensional identity\
  \ matrix.\nThe inverse matrix exists if and only if AAA is invertible. In this case,\n\
  the inverse is unique.\nSupports input of float, double, cfloat and cdouble dtypes.\n\
  Also supports batches of matrices, and if A is a batch of matrices\nthen the output\
  \ has the same batch dimensions.\n\nNote\nWhen inputs are on a CUDA device, this\
  \ function synchronizes that device with the CPU. For a version of this function\
  \ that does not synchronize, see torch.linalg.inv_ex().\n\n\nNote\nConsider using\
  \ torch.linalg.solve() if possible for multiplying a matrix on the left by\nthe\
  \ inverse, as:\nlinalg.solve(A, B) == linalg.inv(A) @ B  # When B is a matrix\n\n\
  \nIt is always preferred to use solve() when possible, as it is faster and more\n\
  numerically stable than computing the inverse explicitly.\n\n\nSee also\ntorch.linalg.pinv()\
  \ computes the pseudoinverse (Moore-Penrose inverse) of matrices\nof any shape.\n\
  torch.linalg.solve() computes A.inv() @ B with a\nnumerically stable algorithm.\n\
  \n\nParameters\nA (Tensor) \u2013 tensor of shape (*, n, n) where * is zero or more\
  \ batch dimensions\nconsisting of invertible matrices.\n\nKeyword Arguments\nout\
  \ (Tensor, optional) \u2013 output tensor. Ignored if None. Default: None.\n\nRaises\n\
  RuntimeError \u2013 if the matrix A or any matrix in the batch of matrices A is\
  \ not invertible.\n\n\nExamples:\n>>> A = torch.randn(4, 4)\n>>> Ainv = torch.linalg.inv(A)\n\
  >>> torch.dist(A @ Ainv, torch.eye(4))\ntensor(1.1921e-07)\n\n>>> A = torch.randn(2,\
  \ 3, 4, 4)  # Batch of matrices\n>>> Ainv = torch.linalg.inv(A)\n>>> torch.dist(A\
  \ @ Ainv, torch.eye(4))\ntensor(1.9073e-06)\n\n>>> A = torch.randn(4, 4, dtype=torch.complex128)\
  \  # Complex matrix\n>>> Ainv = torch.linalg.inv(A)\n>>> torch.dist(A @ Ainv, torch.eye(4))\n\
  tensor(7.5107e-16, dtype=torch.float64)\n\n\n"
